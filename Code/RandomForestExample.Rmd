---
title: "RandomForestExample"
author: "Pedro Beschoren da Costa"
date: "2023-06-07"
output: html_document
editor_options: 
  chunk_output_type: console
---


```{r, setup, include=FALSE}
### you can safely ignore this chunk as a reader ###

# this an an R markdown option for knitting documents, because working directory changes automatically in chunks. if you want details, check https://bookdown.org/yihui/rmarkdown-cookbook/working-directory.html
knitr::opts_knit$set(root.dir = '../')
```

# load libraries

install packages individually as necessary

```{r}

#load packages
library(phyloseq)
library(Boruta)
library(caret)
library(dplyr)
library(tibble)
library(ranger)
library(metagMisc)
library(purrr)

#load a bunch fo custom functions that will helps us
source("./Code/Machine_Learning_custom_functions.R")
```


# load microbiome data as a phyloseq object

a phyloseq object is only a data container, with layers for the feature table (ASVs/OTUs), microbial taxonomies, sample metadata, and reference sequences. 


```{r}
# load object
load("./Data/ps_rarefied.Rdata")

#check ps object
ps_rarefied # full ps object
otu_table(ps_rarefied)[1:5,1:5] # otu table 
tax_table(ps_rarefied)[1:5,] # taxonomy 
ps_rarefied@sam_data [1:5,1:5]# metadata

#let's take a quick look on an oridnation  in this dataset
plot_ordination(ps_rarefied, 
                ordination = ordinate(ps_rarefied, "NMDS", "bray"),
                type="samples", 
                color="Stress")+ theme_bw()+
  theme(legend.position="top")

plot_ordination(ps_rarefied, 
                ordination = ordinate(ps_rarefied, "NMDS", "bray"),
                type="samples", 
                color="Sp_full_name")+ 
  theme_bw()+
  theme(legend.position="top")



``` 

# put data into a format boruta will udenrstand

We will try to predict the variable "Stress", present in our metadata, by using the abudannces of bacteria. "Stress" this refers to the stress treatments we applied to the plants in a greenhouse experiment with different plant species

for classification tasks in borutas, a most critical part of the df is having the variable that you want to predict as a factor. also, make sure you don't ahve NAs, NaN, or empty values in your df

```{r}


# put that microbiome data into a df format that boruta will understand
df_for_boruta_stress<-single_physeq_to_borutaInput(physeq_object = ps_rarefied,
                                             variable_to_be_classified = "Stress")[,-1] # [,-1] removes first column, "sample" as a predictor 

#check the object you have
df_for_boruta_stress[45:55,1:10]
str(df_for_boruta_stress)

#are tehre any NAs?
any(is.na(df_for_boruta_stress))

#is the first column a factor?
is.factor(df_for_boruta_stress[,1])
df_for_boruta_stress[,1]

```

# run boruta

on a 2016 HP Zbook (4 cores, 16GB ram) this takes ~ 4.4 minutes
```{r}

set.seed(101) # set a fixed seed to have reproducible results
boruta_output_stress<-  Boruta(Stress~.,   # classification to predict
                           data = df_for_boruta_stress, # your df with the variable you want to predict
                           doTrace=2, #  verbosity level
                           maxRuns = 60,  # number of iterations
                           ntree = 20000) # size of the forest 

# It's a good practice to save  R objects that take a long time to compute so you don't have to re-run them later
ggsave(boruta_output_stress, file = "./Results/boruta_output_stress.RData")

```


# check boruta object
```{r}

# this is out obruta object
boruta_output_stress

#here you see the importance fo each feature. features with higher importance are better at predicting classifications than features with lwoer importance
attStats(boruta_output_stress)[50:60,]

# check a boxplot of feature importance
plot(boruta_output_stress)

# check feature imortance over itetations
plotImpHistory(boruta_output_stress)

# you can force a solution to tentative features
boruta_output_stress_fixed<-TentativeRoughFix(boruta_output_stress)

# you can now get the features intoa  formula format
boruta_output_stress_fixed_formula<-getConfirmedFormula(boruta_output_stress_fixed)


```



#plot abudnance of ASVs that are good predictos

```{r echo=FALSE}

# get boruta stats of ASVs confirmed to be important
rf_importance_byASV <- 
  filter(attStats(boruta_output_stress_fixed), decision == "Confirmed") %>%
    tibble::rownames_to_column(var = "OTU")

#make ps object that only contains RF-imporantt ASVs
rf_important_ps<-
  prune_taxa(taxa = rf_importance_byASV$OTU,x = ps_rarefied)

# turn ps object into a dataframe
melted_ps <- psmelt(rf_important_ps)

# join melted ps object created above with the boruta stats
rf_ASVs_df <- 
  left_join(melted_ps, rf_importance_byASV)

# quick plot bar with relative abudances, for a quick overview of  data
important_feature_plot<-ggplot(data = rf_ASVs_df, aes(x = OTU, y = Abundance, fill = Stress)) +
    geom_boxplot(aes()) +
    theme_bw() +
    theme(axis.title = element_text(size = 13, face = "bold")) +
    theme(
      panel.border = element_blank(), panel.grid.major = element_blank(),
      panel.grid.minor = element_blank(), axis.line = element_line(colour = "black")
    ) +
    theme(axis.text = element_text(size = 10, face = "bold", colour = "black")) +
    theme(axis.title.x = element_blank()) +
    geom_line(data = rf_ASVs_df, aes(x = OTU, y = meanImp), size = 2) +
    theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))

#save the plot in your results folder
ggsave(important_feature_plot, file = "./Results/important_feature_plot.pdf")

```



# check precision in the predicion of our model with caret

There are many ways to carefully split your data according your experiemntal design. here we will simply ballance according species
```{r}

 # define training and test set. 
  trainIndex<- createDataPartition(df_for_boruta_stress[,1], 
                                   p = .70, 
                                   list = FALSE, 
                                   times = 1)
  # set train and test sets
  data_Train <- df_for_boruta_stress [ trainIndex,]
  data_Test  <- df_for_boruta_stress [-trainIndex,]
  
  #check training and testing sets
  data_Train[30:40,1:10]
  data_Test[30:40,1:10]
  str(data_Test)

```



# train the model
Boruta found the  most important features, but it won't classify new data for you. you have to train the random forest with those boruta-selected features to make a model and test it
```{r}
# define training with 5-folde cross validation repeated 10 times
train.control <- caret::trainControl(method = "repeatedcv", # set trainig/data split 
                                     number = 5,
                                     repeats = 20,
                                     allowParallel = TRUE)
    
#train the model. A small forest with 500 trees takes only a minute
model_borutized <- caret::train(form = boruta_output_stress_fixed_formula, # boruta formula
                                data = data_Train, # training data
                                method = "rf", #  training based on RF
                                trControl = train.control, # defined in trainControl() above
                                ntree=2500) # the more trees, the more precision

#check the trained model
model_borutized

#check your confusion matrix. keep in mind thsi was your traiing set! you should test the model in a new datset the trainer has not seen
confusionMatrix(data =model_borutized )

```


# test the model

```{r}

#predict the labels of your test set
prediction<-stats::predict(object = model_borutized,
                           newdata = data_Test) 

#check if predictions match the true labels
confusion_output<-confusionMatrix(data = prediction, 
                                  reference = data_Test[,1])
 
confusion_output
```


# streamlining the process

This two chunks reproduce the entire pipeline above, twice. edit the custom functions on ./Code/Machine_Learning_custom_functions.R to adapt this to otehr datasets besides microbiome data inside a phyloseq object

```{r message=FALSE}

# this challange should be more difficult, based on the plot
plot_ordination(ps_rarefied, 
                ordination = ordinate(ps_rarefied, "NMDS", "bray"),
                type="samples", 
                color="Stress",
                shape = "Sp_full_name")+ 
  scale_shape_manual(values = c(19, 1, 3)) + 
  theme_bw()+
  theme(legend.position="top")
  


# split the original object by greenhouse comaprtment
ps_stress_l<-  phyloseq_sep_variable(ps_rarefied,variable = c("greenhouse_compartment"))

# run boruta on both sample sets
set.seed(101)
Boruta_stress_l<-lapply(ps_stress_l, function (x) 
  Boruta(Sp_full_name~.,   # classification you are trying to predict
         data = single_physeq_to_borutaInput(physeq_object = x, # df you will give to boruta
                                             variable_to_be_classified = "Sp_full_name")[,-1],
         doTrace=2, 
         maxRuns = 200,  # number fo iterations
         ntree = 100000)) # size of the forest


```

```{r}
# fix the boruta object, split training and test data, train the model, test the model 
CV_output<-fix_stresslit_train_test(boruta_output_l = Boruta_stress_l,
                                ps_object_l = ps_stress_l,
                                variable_to_be_classified = "Sp_full_name" )

     
```

